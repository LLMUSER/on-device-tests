{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdiUW492hRRG4lMlIHMVXJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LLMUSER/on-device-tests/blob/main/Converting_Distill_Bert_SQUAD_to__mlmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8smaP1p6AY3W",
        "outputId": "f98a0564-b773-443e-8b85-99e9eed88945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Collecting coremltools\n",
            "  Downloading coremltools-7.0-cp310-none-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.10/dist-packages (from coremltools) (1.23.5)\n",
            "Requirement already satisfied: protobuf<=4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from coremltools) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from coremltools) (1.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from coremltools) (4.66.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from coremltools) (23.2)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.10/dist-packages (from coremltools) (23.1.0)\n",
            "Collecting cattrs (from coremltools)\n",
            "  Downloading cattrs-23.1.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyaml (from coremltools)\n",
            "  Downloading pyaml-23.9.7-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from cattrs->coremltools) (1.1.3)\n",
            "Requirement already satisfied: typing_extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from cattrs->coremltools) (4.5.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml->coremltools) (6.0.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->coremltools) (1.3.0)\n",
            "Installing collected packages: pyaml, cattrs, coremltools\n",
            "Successfully installed cattrs-23.1.2 coremltools-7.0 pyaml-23.9.7\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install coremltools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "TxW3dCidFEaq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "import torch\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased-distilled-squad')\n",
        "model = DistilBertModel.from_pretrained('distilbert-base-cased-distilled-squad')\n",
        "# print(model)\n",
        "question, text = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\"\n",
        "\n",
        "inputs = tokenizer(question, text, return_tensors=\"pt\")\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMTc_-UWAnR4",
        "outputId": "f575bc6c-d23f-4116-d20e-4480df8face3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaseModelOutput(last_hidden_state=tensor([[[ 1.1810, -0.4073,  0.9986,  ..., -0.7445,  0.0380, -0.5510],\n",
            "         [ 1.6172, -0.6785,  1.6932,  ..., -0.8216, -0.2387, -0.6187],\n",
            "         [ 2.0840, -0.5496,  1.3313,  ..., -0.7791,  0.1698, -0.3950],\n",
            "         ...,\n",
            "         [ 0.2879, -0.1813,  1.2631,  ..., -0.2022,  0.4699,  0.5535],\n",
            "         [ 0.6069, -0.1943,  0.7584,  ..., -0.5106, -0.4027, -0.4910],\n",
            "         [ 1.0183, -0.8215,  0.9088,  ..., -0.8094,  0.8372, -0.2027]]]), hidden_states=None, attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJLr00mKFik_",
        "outputId": "7c5cd038-63f6-48c8-d467-b1580c0342db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  2627,  1108,  3104,  1124, 15703,   136,   102,  3104,  1124,\n",
            "         15703,  1108,   170,  3505, 16797,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a wrapper class for the model\n",
        "import torch.nn as nn\n",
        "class DistillWrapper(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DistillWrapper, self).__init__()\n",
        "    self.model = DistilBertModel.from_pretrained('distilbert-base-cased-distilled-squad')\n",
        "\n",
        "  def forward(self ,x ):\n",
        "    res = self.model(x)\n",
        "    return res['last_hidden_state']\n",
        "\n",
        "traceable_model = DistillWrapper().eval()\n",
        "print(traceable_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23O4H5SBGkUX",
        "outputId": "df3fdcf2-5182-49fd-aa56-341e35ae0dee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistillWrapper(\n",
            "  (model): DistilBertModel(\n",
            "    (embeddings): Embeddings(\n",
            "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): Transformer(\n",
            "      (layer): ModuleList(\n",
            "        (0-5): 6 x TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (activation): GELUActivation()\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trace_model = torch.jit.trace(traceable_model , inputs['input_ids']+inputs['attention_mask'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxQxVGlsFje-",
        "outputId": "59079235-0a88-48cf-c240-b765d88fb839"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py:223: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  mask, torch.tensor(torch.finfo(scores.dtype).min)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import coremltools as ct\n",
        "mlmodel_1 = ct.convert(\n",
        "    trace_model,\n",
        "    convert_to='neuralnetwork',\n",
        "    inputs=[ct.TensorType(name=\"input_ids\", shape=(1,ct.RangeDim(1, 768)))],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDoLAvI7JBqF",
        "outputId": "a32e5370-7f64-4601-9c19-b2e0906cdf6f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting PyTorch Frontend ==> MIL Ops:   0%|          | 0/289 [00:00<?, ? ops/s]WARNING:coremltools:Core ML embedding (gather) layer does not support any inputs besides the weights and indices. Those given will be ignored.\n",
            "Converting PyTorch Frontend ==> MIL Ops: 100%|█████████▉| 288/289 [00:01<00:00, 241.92 ops/s]\n",
            "Running MIL frontend_pytorch pipeline: 100%|██████████| 5/5 [00:00<00:00, 93.27 passes/s]\n",
            "Running MIL default pipeline:  15%|█▌        | 10/65 [00:00<00:01, 42.52 passes/s]/usr/local/lib/python3.10/dist-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:267: UserWarning: Output, '469', of the source model, has been renamed to 'var_469' in the Core ML model.\n",
            "  warnings.warn(msg.format(var.name, new_name))\n",
            "Running MIL default pipeline: 100%|██████████| 65/65 [00:02<00:00, 28.08 passes/s]\n",
            "Running MIL backend_neuralnetwork pipeline: 100%|██████████| 9/9 [00:00<00:00, 449.98 passes/s]\n",
            "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 385/385 [00:10<00:00, 36.32 ops/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlmodel_1.save(\"DistillBertFinetunedSquad.mlmodel\")"
      ],
      "metadata": {
        "id": "cBxnt9qyJoTi"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}